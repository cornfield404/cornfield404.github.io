<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>DDPM | Corn Field</title><meta name="author" content="Corn"><meta name="copyright" content="Corn"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="题目： Denoising Diffusion Probabilistic Models链接： https:&#x2F;&#x2F;arxiv.org&#x2F;format&#x2F;2006.11239代码： https:&#x2F;&#x2F;github.com&#x2F;hojonathanho&#x2F;diffusion来源： NIPS 2020单位： UC Berkeley  模型总览">
<meta property="og:type" content="article">
<meta property="og:title" content="DDPM">
<meta property="og:url" content="https://cornfield404.github.io/posts/f0775513/index.html">
<meta property="og:site_name" content="Corn Field">
<meta property="og:description" content="题目： Denoising Diffusion Probabilistic Models链接： https:&#x2F;&#x2F;arxiv.org&#x2F;format&#x2F;2006.11239代码： https:&#x2F;&#x2F;github.com&#x2F;hojonathanho&#x2F;diffusion来源： NIPS 2020单位： UC Berkeley  模型总览">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cornfield404.github.io/img/avatar.jpg">
<meta property="article:published_time" content="2024-12-26T10:35:25.000Z">
<meta property="article:modified_time" content="2024-12-27T05:14:18.080Z">
<meta property="article:author" content="Corn">
<meta property="article:tag" content="论文笔记">
<meta property="article:tag" content="Diffusion">
<meta property="article:tag" content="Image_Generation">
<meta property="article:tag" content="高引">
<meta property="article:tag" content="NIPS2020">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cornfield404.github.io/img/avatar.jpg"><link rel="shortcut icon" href="/img/butterfly-icon.png"><link rel="canonical" href="https://cornfield404.github.io/posts/f0775513/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'DDPM',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  isShuoshuo: false
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><div class="loading-img"></div><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (false) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><script>window.paceOptions = {
  restartOnPushState: false
}

btf.addGlobalFn('pjaxSend', () => {
  Pace.restart()
}, 'pace_restart')

</script><link rel="stylesheet" href="/css/progress_bar.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js/pace.min.js"></script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">35</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">44</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-book"></i><span> 技术积累</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"><i class="fa-fw fa fa-code"></i><span> 编程技巧</span></a></li><li><a class="site-page child" href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><i class="fa-fw fa fa-newspaper"></i><span> 论文笔记</span></a></li><li><a class="site-page child" href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"><i class="fa-fw fa fa-book-open"></i><span> 读书笔记</span></a></li><li><a class="site-page child" href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"><i class="fa-fw fa fa-paperclip"></i><span> 杂七杂八</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-clapperboard"></i><span> 休闲娱乐</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/%E4%BC%91%E9%97%B2%E5%A8%B1%E4%B9%90/%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB/"><i class="fa-fw fa fa-book-open-reader"></i><span> 书籍阅读</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-camera"></i><span> 生活琐事</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/%E7%94%9F%E6%B4%BB%E7%90%90%E4%BA%8B/%E7%A5%9E%E5%A5%87%E6%8A%80%E8%83%BD/"><i class="fa-fw fa fa-person-skating"></i><span> 神奇技能</span></a></li><li><a class="site-page child" href="/categories/%E7%94%9F%E6%B4%BB%E7%90%90%E4%BA%8B/%E7%82%B9%E7%82%B9%E6%BB%B4%E6%BB%B4/"><i class="fa-fw fa fa-puzzle-piece"></i><span> 点点滴滴</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-folder-open"></i><span> 整理</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-th"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-bars"></i><span> 其他</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/random.html"><i class="fa-fw fas fa-random"></i><span> 随便逛逛</span></a></li><li><a class="site-page child" href="/artitalk/"><i class="fa-fw fa fa-heartbeat"></i><span> 碎碎念</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fa fa-user"></i><span> 关于我</span></a></li><li><a class="site-page child" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/sitemap.xml"><i class="fa-fw fa fa-sitemap"></i><span> 站点地图</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://yumiwawa-1300546587.cos.ap-beijing.myqcloud.com/Obsidian/background.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Corn Field</span></a><a class="nav-page-title" href="/"><span class="site-name">DDPM</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-book"></i><span> 技术积累</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"><i class="fa-fw fa fa-code"></i><span> 编程技巧</span></a></li><li><a class="site-page child" href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><i class="fa-fw fa fa-newspaper"></i><span> 论文笔记</span></a></li><li><a class="site-page child" href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"><i class="fa-fw fa fa-book-open"></i><span> 读书笔记</span></a></li><li><a class="site-page child" href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"><i class="fa-fw fa fa-paperclip"></i><span> 杂七杂八</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-clapperboard"></i><span> 休闲娱乐</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/%E4%BC%91%E9%97%B2%E5%A8%B1%E4%B9%90/%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB/"><i class="fa-fw fa fa-book-open-reader"></i><span> 书籍阅读</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-camera"></i><span> 生活琐事</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/%E7%94%9F%E6%B4%BB%E7%90%90%E4%BA%8B/%E7%A5%9E%E5%A5%87%E6%8A%80%E8%83%BD/"><i class="fa-fw fa fa-person-skating"></i><span> 神奇技能</span></a></li><li><a class="site-page child" href="/categories/%E7%94%9F%E6%B4%BB%E7%90%90%E4%BA%8B/%E7%82%B9%E7%82%B9%E6%BB%B4%E6%BB%B4/"><i class="fa-fw fa fa-puzzle-piece"></i><span> 点点滴滴</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-folder-open"></i><span> 整理</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-th"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-bars"></i><span> 其他</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/random.html"><i class="fa-fw fas fa-random"></i><span> 随便逛逛</span></a></li><li><a class="site-page child" href="/artitalk/"><i class="fa-fw fa fa-heartbeat"></i><span> 碎碎念</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fa fa-user"></i><span> 关于我</span></a></li><li><a class="site-page child" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/sitemap.xml"><i class="fa-fw fa fa-sitemap"></i><span> 站点地图</span></a></li></ul></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">DDPM</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-12-26T10:35:25.000Z" title="发表于 2024-12-26 18:35:25">2024-12-26</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-12-27T05:14:18.080Z" title="更新于 2024-12-27 13:14:18">2024-12-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/">技术积累</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p><strong>题目：</strong> Denoising Diffusion Probabilistic Models<br><strong>链接：</strong> <a target="_blank" rel="noopener" href="https://arxiv.org/format/2006.11239">https://arxiv.org/format/2006.11239</a><br><strong>代码：</strong> <a target="_blank" rel="noopener" href="https://github.com/hojonathanho/diffusion">https://github.com/hojonathanho/diffusion</a><br><strong>来源：</strong> NIPS 2020<br><strong>单位：</strong> UC Berkeley</p>
<hr>
<h4 id="模型总览"><a href="#模型总览" class="headerlink" title="模型总览"></a>模型总览</h4><p><img src="https://yumiwawa-1300546587.cos.ap-beijing.myqcloud.com/Obsidian/%25E6%2588%25AA%25E5%25B1%258F2023-08-11%252017.10.55.png" alt="截屏2023-08-11 17.10.55.png"></p>
<p>DDPM 模型主要分为两个过程：forward 加噪过程（从右往左）和 reverse 去噪过程（从左往右）。加噪过程意思是指向数据集的真实图片中逐步加入高斯噪声，而去噪过程是指对加了噪声的图片逐步去噪，从而还原出真实图片。加噪过程满足一定的数学规律，而去噪过程则采用神经网络来学习。这么一来，神经网络就可以从一堆杂乱无章的噪声图片中生成真实图片了。</p>
<hr>
<h4 id="Diffusion-扩散过程（Forward-加噪过程）"><a href="#Diffusion-扩散过程（Forward-加噪过程）" class="headerlink" title="Diffusion 扩散过程（Forward 加噪过程）"></a>Diffusion 扩散过程（Forward 加噪过程）</h4><h5 id="数学基础"><a href="#数学基础" class="headerlink" title="数学基础"></a>数学基础</h5><h6 id="马尔可夫性质"><a href="#马尔可夫性质" class="headerlink" title="马尔可夫性质"></a>马尔可夫性质</h6><p>马尔可夫性质是概率论中的一个概念，因为俄国数学家安德雷·马尔可夫得名。当一个随机过程在给定现在状态及所有过去状态情况下，其未来状态的条件概率分布仅依赖于当前状态；换句话说，在给定现在状态时，它与过去状态（即该过程的历史路径）是条件独立的，那么此随机过程即具有马尔可夫性质。具有马尔可夫性质的过程通常称之为马尔可夫过程。</p>
<h6 id="高斯分布的独立可加性"><a href="#高斯分布的独立可加性" class="headerlink" title="高斯分布的独立可加性"></a>高斯分布的独立可加性</h6><p>若：</p>

$$
\begin{align}
X &\sim N(\mu_X,\sigma_X^2) \\
Y &\sim N(\mu_Y,\sigma_Y^2) \\
Z &= X+Y
\end{align}
$$

<p>则：<br>$$<br>\begin{align}<br>Z&amp;\sim N(\mu_X+\mu_Y,\sigma_X^2+\sigma_Y^2)<br>\end{align}<br>$$</p>
<h5 id="逐步加噪过程"><a href="#逐步加噪过程" class="headerlink" title="逐步加噪过程"></a>逐步加噪过程</h5><p>向数据分布中逐渐加入高斯噪声，加噪过程持续​ $T$ 次，产生一系列带噪声的图片 $x_1,…,x_T$。在由 $x_{t-1}$ 加噪至 $x_t$ 的过程中，噪声的标准差/方差是以一个在区间 $(0,1)$ 内的固定值 $\beta_T$ 来确定的，均值是以固定值 $\beta_T$ 和当前时刻的图片数据 $x_{t-1}$ 来确定的。<br>以上描述的加噪过程可以写成公式：</p>

$$
\begin{align}
q(x_t|x_{t-1})&=\mathcal{N}(x_t;\sqrt{1-\beta_t}x_{t-1},\beta_t\mathbf{I}) \\
q(x_{1:T}|x_0)&=\prod_{t=1}^Tq(x_t|x_{t-1}) 
\end{align}
$$

<p>这个噪声只由 $\beta_T$ 和 $x_{t-1}$ 决定，是一个固定值，而非可学习过程。因此，只要有了 $x_0$，并且提前确定每一步的固定值 $\beta_1,…,\beta_T$，就可以推出任意一步的加噪数据 $x_1,…,x_T$。整个加噪过程是一个马尔可夫过程。</p>
<h5 id="加噪结果"><a href="#加噪结果" class="headerlink" title="加噪结果"></a>加噪结果</h5><p>随着​ $t$ 的不断增大，最终原始数据​ $x_0$ 会逐步失去它的特征。最终当 $T\rightarrow\infty$ ​时，$x_T$ 趋近于一个各向独立的高斯分布。从视觉上来看，就是将原本一张完好的照片加噪很多步后，图片几乎变成了一张完全是噪声的图片。</p>
<h5 id="任意时刻数据-x-t-的计算"><a href="#任意时刻数据-x-t-的计算" class="headerlink" title="任意时刻数据 $x_t$ 的计算"></a>任意时刻数据 $x_t$ 的计算</h5><p>在逐步加噪的过程中，其实并不需要一步一步地从 $x_0,x_1,…$ 去迭代得到 $x_t$，可以直接从 $x_0$ 和固定序列值 $\{\beta_T\in(0,1)\}_{t=1}^T$ 计算得到。</p>

$$
\begin{align}
x_t&=\sqrt{1-\beta_t}x_{t-1}+\sqrt{\beta_t}z_1,&where\ z_1,z_2,\ldots,\sim\mathcal{N}(0,\mathbf{I}) \\
&=\sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}z_1\\
&=\sqrt{\alpha_t}(\sqrt{\alpha_{t-1}}x_{t-2}+\sqrt{1-\alpha_{t-1}}z_2)+\sqrt{1-\alpha_t}z_1\\
&=\sqrt{\alpha_t\alpha_{t-1}}x_{t-2}+\sqrt{\alpha_t}\sqrt{1-\alpha_{t-1}}z_2+\sqrt{1-\alpha_t}z_1\\
&=\sqrt{\alpha_t\alpha_{t-1}}x_{t-2}+\sqrt{1-a_ta_{t-1}}\overline{z_2},&\overline{z_2}\sim \mathcal{N}(0,\mathbf{I})\\
&=\ldots\\
&=\sqrt{\alpha_t\alpha_{t-1}\ldots\alpha_1}x_0+\sqrt{1-a_ta_{t-1}\ldots\alpha_1}\overline{z_t}\\
&=\sqrt{\overline{\alpha_t}}x_0+\sqrt{1-\overline{\alpha_t}}\cdot\overline{z_t}
\end{align}
$$

<p>由上式可得：</p>

$$
q(x_t|x_0)=\mathcal{N}(x_t;\sqrt{\overline{\alpha_t}}x_0,(1-\overline{\alpha_t})\mathbf{I})
$$

<p>由此公式可以看出，只要有了 $x_0$ 和固定值序列 $\{\beta_T\in(0,1)\}_{t=1} ^T$ ，再从标准分布 $N(0,1)$ 采样出一个 $z$，就可以直接计算出 $x_t$ 了。</p>
<p>在最终的等式中，$x_t=\sqrt{\overline{a_t}}x_0+\sqrt{1-\overline{a_t}}\cdot \overline{z_t}$，其中 $\overline{a_t}=\prod_{i=1}^T\alpha_i$ 在 $T$ 次连乘之后接近于 0。因此 $x_t$ 接近于 $0\times x_0+\sqrt{1-0}\overline{z_t}=\overline{z_t}$，即：$\mathcal{N}(0,\mathbf{I})$ 的正态分布。</p>
<h5 id="beta-t-的取值设置"><a href="#beta-t-的取值设置" class="headerlink" title="$\beta_t$ 的取值设置"></a>$\beta_t$ 的取值设置</h5><p>一般地，随着​ $t$ 的增大，数据越接近随机的高斯分布，$\beta_t$ 的取值就越大。所以 $\beta_1&lt;\beta_2&lt;\ldots&lt;\beta_T$。同时，由于 $\{\beta_T\in(0,1)\}_{t=1}^T$，即 $\beta_1,\beta_2,\ldots,\beta_T$ 的取值区间在 $(0,1)$ 内，因此 $\alpha_1,\alpha_2,\ldots,\alpha_T$ 的取值也在 $(0,1)$ 内。所以，$\overline{\alpha_1}&gt;\overline{\alpha_2}&gt;\ldots&gt;\overline{\alpha_T}$。</p>
<hr>
<h4 id="Reverse-Diffusion-逆扩散过程（Reverse-去噪过程）"><a href="#Reverse-Diffusion-逆扩散过程（Reverse-去噪过程）" class="headerlink" title="Reverse Diffusion 逆扩散过程（Reverse 去噪过程）"></a>Reverse Diffusion 逆扩散过程（Reverse 去噪过程）</h4><h5 id="数学基础-1"><a href="#数学基础-1" class="headerlink" title="数学基础"></a>数学基础</h5><h6 id="贝叶斯公式"><a href="#贝叶斯公式" class="headerlink" title="贝叶斯公式"></a>贝叶斯公式</h6><p>用来描述两个条件概率之间的关系。按照乘法法则：<br>$$<br>P(A\cap B)=P(A)\times P(B|A)=P(B)\times P(A|B)<br>$$<br>变形可得：<br>$$<br>P(A|B)=P(A)\times P(B|A)/P(B)<br>$$</p>
<h5 id="后验扩散条件概率-q-x-t-1-x-t-x-0"><a href="#后验扩散条件概率-q-x-t-1-x-t-x-0" class="headerlink" title="后验扩散条件概率 $q(x_{t-1}|x_t,x_0)$"></a>后验扩散条件概率 $q(x_{t-1}|x_t,x_0)$</h5><p>在逆扩散过程中，如果给定了 $x_t$ 和 $x_0$，就可以计算出 $x_{t-1}$，即后验条件概率 $q(x_{t-1}|x_t,x_0)$ 是可以计算的：</p>

$$
\begin{align}
q(x_{t-1}|x_t,x_0)&=q(x_t|x_{t-1},x_0)\frac{q(x_{t-1}|x_0)}{q(x_t|x_0)}
\end{align}
$$

<p>由正向加噪过程可知：</p>

$$
\begin{align}
q(x_t|x_{t-1},x_0)&=\sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}z_1&～\mathcal{N}(\sqrt{\alpha_t}x_{t-1},1-\alpha_t) \\
q(x_{t-1}|x_0)&=\sqrt{\overline{\alpha_{t-1}}}x_0+\sqrt{1-\overline{\alpha_{t-1}}}\cdot\overline{z_{t-1}}&～\mathcal{N}(\sqrt{\overline{\alpha_{t-1}}}x_0,1-\overline{\alpha_{t-1}}) \\
q(x_t|x_0)&=\sqrt{\overline{\alpha_t}}x_0+\sqrt{1-\overline{\alpha_t}}\cdot\overline{z_{t-1}}&～\mathcal{N}(\sqrt{\overline{\alpha_t}}x_0,1-\overline{\alpha_t})
\end{align}
$$

<p>正态分布可以表示为：$N(\mu, \sigma ^2)\propto\exp(-\frac{(x-\mu)^2}{2\sigma ^2})$<br>推导可知：</p>

$$
\begin{align}
q(x_{t-1}|x_t,x_0)&\propto \exp(-\frac{1}{2}(\frac{(x_t-\sqrt{\alpha_t}x_{t-1})^2}{\beta_t}+\frac{(x_{t-1}-\sqrt{\overline{\alpha_{t-1}}}x_0)^2}{1-\overline{\alpha_{t-1}}}-\frac{(x_t-\sqrt{\overline{\alpha_t}}x_0)^2}{1-\overline{\alpha_t}})) \\
&\propto \exp(-\frac{1}{2}((\frac{\alpha_t}{\beta_t}+\frac{1}{1-\overline{\alpha_{t-1}}})x_{t-1}^2-(\frac{2\sqrt{\alpha_t}x_t}{\beta_t}+\frac{2\sqrt{\overline{\alpha_{t-1}}}x_0}{1-\overline{\alpha_{t-1}}})x_{t-1}+C(x_t,x_0)))
\end{align}
$$

<p>对比正态分布公式，可以推出：</p>

$$
\begin{align}
\sigma^2&=\frac{1}{\frac{\alpha_t}{\beta_t}+\frac{1}{1-\overline{\alpha_{t-1}}}}=\frac{1-\overline{\alpha_{t-1}}}{1-\overline{\alpha_t}}\beta_t \\
\mu&=(\frac{\sqrt{\alpha_t}x_t}{\beta_t}+\frac{\sqrt{\overline{\alpha_{t-1}}}x_0}{1-\overline{\alpha_{t-1}}})\cdot \frac{1}{\frac{\alpha_t}{\beta_t}+\frac{1}{1-\overline{\alpha_{t-1}}}}=\frac{(1-\overline{\alpha_{t-1}})\sqrt{\alpha_t}}{1-\overline{\alpha_t}}x_t+\frac{\sqrt{\overline{\alpha_{t-1}}}\beta_t}{1-\overline{\alpha_t}}x_0
\end{align}
$$

<p>把 $x_0$ 用 $x_t$ 替换掉可得：</p>

$$
\begin{align}
\mu&=\frac{(1-\overline{\alpha_{t-1}})\sqrt{\alpha_t}}{1-\overline{\alpha_t}}x_t+\frac{\sqrt{\overline{\alpha_{t-1}}}\beta_t}{1-\overline{\alpha_t}}x_0 \\
&=\frac{(1-\overline{\alpha_{t-1}})\sqrt{\alpha_t}}{1-\overline{\alpha_t}}x_t+\frac{\sqrt{\overline{\alpha_{t-1}}}\beta_t}{1-\overline{\alpha_t}}\cdot \frac{x_t-\sqrt{1-\overline{\alpha_t}}\cdot \overline{z_t}}{\sqrt{\overline{\alpha_t}}}\\
&=\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\overline{\alpha_t}}}\cdot \overline{z_t})
\end{align}
$$

<p>这里可以看出想要推导出前一张图只有 $\overline{z_t}$ 是未知的，所以只要用网络预测出这个 $\overline{z_t}$ 就可以了。</p>
<hr>
<h4 id="个人理解"><a href="#个人理解" class="headerlink" title="个人理解"></a>个人理解</h4><p>直观上 diffusion model 是个比较好理解的模型，向图像中一步步加噪使图像变成一个完全的随机噪声，反过来，只要预测出每一步加入的噪声，就可以得到原始的图像。只不过论文中用了复杂的公式给这一过程进行了严密的论证，论证了只需要预测出噪声就可以一步步推导出上一步的图像，也论证了仅用加入的噪声作为监督信息就可以预测出原始图像。</p>
<p>从代码里也可以看出 diffusion model 的实现非常简洁：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Diffusion</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, noise_steps=<span class="number">1000</span>, beta_start=<span class="number">1e-4</span>, beta_end=<span class="number">0.02</span>, img_size=<span class="number">256</span>, device=<span class="string">&quot;cuda&quot;</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.noise_steps = noise_steps</span><br><span class="line">        <span class="variable language_">self</span>.beta_start = beta_start</span><br><span class="line">        <span class="variable language_">self</span>.beta_end = beta_end</span><br><span class="line">        <span class="variable language_">self</span>.img_size = img_size</span><br><span class="line">        <span class="variable language_">self</span>.device = device</span><br><span class="line">        </span><br><span class="line">        <span class="variable language_">self</span>.beta = <span class="variable language_">self</span>.prepare_noise_schedule().to(device)</span><br><span class="line">        <span class="variable language_">self</span>.alpha = <span class="number">1.</span> - <span class="variable language_">self</span>.beta</span><br><span class="line">        <span class="variable language_">self</span>.alpha_hat = torch.cumprod(<span class="variable language_">self</span>.alpha, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用于计算每一步加入噪声的强弱，这里采用了一个线性增加的方式</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">prepare_noise_schedule</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> torch.linspace(<span class="variable language_">self</span>.beta_start, <span class="variable language_">self</span>.beta_end, <span class="variable language_">self</span>.noise_steps)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算加噪后的图像，由原始图像，噪声以及加噪比例决定</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">noise_images</span>(<span class="params">self, x, t</span>):</span><br><span class="line">        sqrt_alpha_hat = torch.sqrt(<span class="variable language_">self</span>.alpha_hat[t])[:, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>]</span><br><span class="line">        sqrt_one_minus_alpha_hat = torch.sqrt(<span class="number">1</span> - <span class="variable language_">self</span>.alpha_hat[t])[:, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>]</span><br><span class="line">        Ɛ = torch.randn_like(x)</span><br><span class="line">        <span class="keyword">return</span> sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * Ɛ, Ɛ</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sample_timesteps</span>(<span class="params">self, n</span>):</span><br><span class="line">        <span class="keyword">return</span> torch.randint(low=<span class="number">1</span>, high=<span class="variable language_">self</span>.noise_steps, size=(n,))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据推导的逆扩散过程的公式逐步推出上一张图</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sample</span>(<span class="params">self, model, n</span>):</span><br><span class="line">        logging.info(<span class="string">f&quot;Sampling <span class="subst">&#123;n&#125;</span> new images....&quot;</span>)</span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            x = torch.randn((n, <span class="number">3</span>, <span class="variable language_">self</span>.img_size, <span class="variable language_">self</span>.img_size)).to(<span class="variable language_">self</span>.device)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">reversed</span>(<span class="built_in">range</span>(<span class="number">1</span>, <span class="variable language_">self</span>.noise_steps)), position=<span class="number">0</span>):</span><br><span class="line">                t = (torch.ones(n) * i).long().to(<span class="variable language_">self</span>.device)</span><br><span class="line">                predicted_noise = model(x, t)</span><br><span class="line">                alpha = <span class="variable language_">self</span>.alpha[t][:, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>]</span><br><span class="line">                alpha_hat = <span class="variable language_">self</span>.alpha_hat[t][:, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>]</span><br><span class="line">                beta = <span class="variable language_">self</span>.beta[t][:, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>]</span><br><span class="line">                <span class="keyword">if</span> i &gt; <span class="number">1</span>:</span><br><span class="line">                    noise = torch.randn_like(x)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    noise = torch.zeros_like(x)</span><br><span class="line">                x = <span class="number">1</span> / torch.sqrt(alpha) * (x - ((<span class="number">1</span> - alpha) / (torch.sqrt(<span class="number">1</span> - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise</span><br><span class="line">        model.train()</span><br><span class="line">        x = (x.clamp(-<span class="number">1</span>, <span class="number">1</span>) + <span class="number">1</span>) / <span class="number">2</span></span><br><span class="line">        x = (x * <span class="number">255</span>).<span class="built_in">type</span>(torch.uint8)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">args</span>):</span><br><span class="line">    setup_logging(args.run_name)</span><br><span class="line">    device = args.device</span><br><span class="line">    dataloader = get_data(args)</span><br><span class="line">    model = UNet().to(device)</span><br><span class="line">    optimizer = optim.AdamW(model.parameters(), lr=args.lr)</span><br><span class="line">    mse = nn.MSELoss()</span><br><span class="line">    diffusion = Diffusion(img_size=args.image_size, device=device)</span><br><span class="line">    logger = SummaryWriter(os.path.join(<span class="string">&quot;runs&quot;</span>, args.run_name))</span><br><span class="line">    l = <span class="built_in">len</span>(dataloader)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.epochs):</span><br><span class="line">        logging.info(<span class="string">f&quot;Starting epoch <span class="subst">&#123;epoch&#125;</span>:&quot;</span>)</span><br><span class="line">        pbar = tqdm(dataloader)</span><br><span class="line">        <span class="keyword">for</span> i, (images, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(pbar):</span><br><span class="line">            images = images.to(device)</span><br><span class="line">            t = diffusion.sample_timesteps(images.shape[<span class="number">0</span>]).to(device)</span><br><span class="line">            x_t, noise = diffusion.noise_images(images, t)</span><br><span class="line">            predicted_noise = model(x_t, t)</span><br><span class="line">            loss = mse(noise, predicted_noise)</span><br><span class="line"></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            pbar.set_postfix(MSE=loss.item())</span><br><span class="line">            logger.add_scalar(<span class="string">&quot;MSE&quot;</span>, loss.item(), global_step=epoch * l + i)</span><br><span class="line"></span><br><span class="line">        sampled_images = diffusion.sample(model, n=images.shape[<span class="number">0</span>])</span><br><span class="line">        save_images(sampled_images, os.path.join(<span class="string">&quot;results&quot;</span>, args.run_name, <span class="string">f&quot;<span class="subst">&#123;epoch&#125;</span>.jpg&quot;</span>))</span><br><span class="line">        torch.save(model.state_dict(), os.path.join(<span class="string">&quot;models&quot;</span>, args.run_name, <span class="string">f&quot;ckpt.pt&quot;</span>))</span><br></pre></td></tr></table></figure>

<hr>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://cornfield404.github.io">Corn</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://cornfield404.github.io/posts/f0775513/">https://cornfield404.github.io/posts/f0775513/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://cornfield404.github.io" target="_blank">Corn Field</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a><a class="post-meta__tags" href="/tags/Diffusion/">Diffusion</a><a class="post-meta__tags" href="/tags/Image-Generation/">Image_Generation</a><a class="post-meta__tags" href="/tags/%E9%AB%98%E5%BC%95/">高引</a><a class="post-meta__tags" href="/tags/NIPS2020/">NIPS2020</a></div><div class="post-share"><div class="social-share" data-image="/img/avatar.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/posts/826780ab/" title="SDXL"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">SDXL</div></div><div class="info-2"><div class="info-item-1">题目： SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis链接： https://arxiv.org/pdf/2307.01952代码： https://github.com/Stability-AI/generative-models来源： ICLR 2024单位： Stability AI, Applied Research  本文目的在 stable diffusion 基础上，提升生成效果。  Method模型相比之前的主要调整  模型结构上，删掉 unet lowest level，highest level 里不加 transformer block，中间两层 level 分别加入 2 个和 10 个 transformer block； Text encoder 采用两个 encoder 输出 concat 的结果； 加入了 pooled text embedding。  Conditioning the Model on Image Size因为 latent...</div></div></div></a><a class="pagination-related" href="/posts/57e95ee9/" title="InstructSeg"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">InstructSeg</div></div><div class="info-2"><div class="info-item-1">题目： InstructSeg: Unifying Instructed Visual Segmentation with Multi-modal Large Language Models链接： https://arxiv.org/pdf/2412.14006代码： https://github.com/congvvc/InstructSeg来源： arxiv单位： Tsinghua Shenzhen International Graduate School, Tsinghua University；Meituan Inc.  本文目的为图像和视频的 referring segmentation 和 reasoning segmentation 设计一个统一的 end-to-end 框架。  Method Object-aware Video Perceiver该模块根据输入的待分割视频帧及文本信息，提取 query 特征：   $$ \begin{align} f_r^t&=F_{CLIP}(I_r^t)...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/posts/826780ab/" title="SDXL"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-27</div><div class="info-item-2">SDXL</div></div><div class="info-2"><div class="info-item-1">题目： SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis链接： https://arxiv.org/pdf/2307.01952代码： https://github.com/Stability-AI/generative-models来源： ICLR 2024单位： Stability AI, Applied Research  本文目的在 stable diffusion 基础上，提升生成效果。  Method模型相比之前的主要调整  模型结构上，删掉 unet lowest level，highest level 里不加 transformer block，中间两层 level 分别加入 2 个和 10 个 transformer block； Text encoder 采用两个 encoder 输出 concat 的结果； 加入了 pooled text embedding。  Conditioning the Model on Image Size因为 latent...</div></div></div></a><a class="pagination-related" href="/posts/16f61640/" title="latent diffusion"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-20</div><div class="info-item-2">latent diffusion</div></div><div class="info-2"><div class="info-item-1">题目： High-Resolution Image Synthesis with Latent Diffusion Models链接： https://arxiv.org/pdf/2112.10752代码： https://github.com/CompVis/latent-diffusion来源： CVPR 2022单位： Ludwig Maximilian University of Munich &amp; IWR, Heidelberg University, Germany；Runway ML  本文希望解决的问题及解决方案本文想要解决的问题是 Diffusion Model 训练和推理成本都过高。文章中认为 diffusion model 在每个像素上计算是没必要的，因此希望找到一个等效空间，在该空间上进行 diffusion 操作。  Method Perceptual Image Compression训练一个 autoencoder 把图像压缩到 latent space 中。因为 diffusion model 本身是在二维空间上操作的，因此本文压缩后的...</div></div></div></a><a class="pagination-related" href="/posts/9feacd8a/" title="P-Tuning v2"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-22</div><div class="info-item-2">P-Tuning v2</div></div><div class="info-2"><div class="info-item-1">题目： P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks链接： https://arxiv.org/pdf/2110.07602代码： https://github.com/THUDM/P-tuning-v2来源： ACL 2022单位： Tsinghua University, KEG；Beijing Academy of Artificial Intelligence (BAAI)；Shanghai Qi Zhi Institute  Motivation对于大模型 finetune 所有参数很困难，类似 P-Tuning 的 prompt tuning 方法性能比 finetune 所有参数差，尤其在模型参数规模不足 100 亿时效果差的更明显。本文希望找到一种泛化性更强的 prompt tuning 方法。  P-Tuning 缺陷 在小模型上效果不好，当模型参数量大于 100 亿时，与 finetune...</div></div></div></a><a class="pagination-related" href="/posts/8c1493e0/" title="P-Tuning"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-22</div><div class="info-item-2">P-Tuning</div></div><div class="info-2"><div class="info-item-1">题目： GPT Understands, Too链接： https://arxiv.org/pdf/2103.10385代码： https://github.com/THUDM/P-tuning来源： AI Open 2024单位： Tsinghua University；Massachusetts Institute of Technology  MotivationPrompt 可以提升大语言模型性能，然而，人工提供的离散 prompt 会导致很大的不确定性，几个单词的变动就会导致结果发生大幅度变化。P-Tuning 希望在离散的 prompt 前加入一个可训练的连续 prompt，提升稳定性。  Method  </div></div></div></a><a class="pagination-related" href="/posts/3a5bfa54/" title="LoRA"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-15</div><div class="info-item-2">LoRA</div></div><div class="info-2"><div class="info-item-1">题目： LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS链接： https://arxiv.org/pdf/2106.09685代码： https://github.com/microsoft/LoRA来源： ICLR 2022单位： Microsoft Corporation  Motivation随着模型规模越来越大，在所有参数上 finetune 越来越不现实。之前提出的解决方案都有一定缺陷：  增加 adapter layer 会引入额外的延迟，且当 batch size 减小时这种延迟变得不可忽视； Optimizing prompt 难以训练，且保留一部分 prompt 会导致下游任务可用的 prompt 长度变小，从而影响模型整体性能。   Method假设在 finetune 过程中权重矩阵的变化量是低秩的，即：$W_0+\Delta W=W_0+BA$，其中：$B\in \mathbb{R}^{d\times r}$，$A\in \mathbb{R}^{r\times k}$ 且 $r\ll \min(d,...</div></div></div></a><a class="pagination-related" href="/posts/57e95ee9/" title="InstructSeg"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-26</div><div class="info-item-2">InstructSeg</div></div><div class="info-2"><div class="info-item-1">题目： InstructSeg: Unifying Instructed Visual Segmentation with Multi-modal Large Language Models链接： https://arxiv.org/pdf/2412.14006代码： https://github.com/congvvc/InstructSeg来源： arxiv单位： Tsinghua Shenzhen International Graduate School, Tsinghua University；Meituan Inc.  本文目的为图像和视频的 referring segmentation 和 reasoning segmentation 设计一个统一的 end-to-end 框架。  Method Object-aware Video Perceiver该模块根据输入的待分割视频帧及文本信息，提取 query 特征：   $$ \begin{align} f_r^t&=F_{CLIP}(I_r^t)...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Corn</div><div class="author-info-description">来者可追</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">35</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">44</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%80%BB%E8%A7%88"><span class="toc-number">1.</span> <span class="toc-text">模型总览</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Diffusion-%E6%89%A9%E6%95%A3%E8%BF%87%E7%A8%8B%EF%BC%88Forward-%E5%8A%A0%E5%99%AA%E8%BF%87%E7%A8%8B%EF%BC%89"><span class="toc-number">2.</span> <span class="toc-text">Diffusion 扩散过程（Forward 加噪过程）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80"><span class="toc-number">2.1.</span> <span class="toc-text">数学基础</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%80%A7%E8%B4%A8"><span class="toc-number">2.1.1.</span> <span class="toc-text">马尔可夫性质</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E7%9A%84%E7%8B%AC%E7%AB%8B%E5%8F%AF%E5%8A%A0%E6%80%A7"><span class="toc-number">2.1.2.</span> <span class="toc-text">高斯分布的独立可加性</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%80%90%E6%AD%A5%E5%8A%A0%E5%99%AA%E8%BF%87%E7%A8%8B"><span class="toc-number">2.2.</span> <span class="toc-text">逐步加噪过程</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8A%A0%E5%99%AA%E7%BB%93%E6%9E%9C"><span class="toc-number">2.3.</span> <span class="toc-text">加噪结果</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BB%BB%E6%84%8F%E6%97%B6%E5%88%BB%E6%95%B0%E6%8D%AE-x-t-%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="toc-number">2.4.</span> <span class="toc-text">任意时刻数据 $x_t$ 的计算</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#beta-t-%E7%9A%84%E5%8F%96%E5%80%BC%E8%AE%BE%E7%BD%AE"><span class="toc-number">2.5.</span> <span class="toc-text">$\beta_t$ 的取值设置</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Reverse-Diffusion-%E9%80%86%E6%89%A9%E6%95%A3%E8%BF%87%E7%A8%8B%EF%BC%88Reverse-%E5%8E%BB%E5%99%AA%E8%BF%87%E7%A8%8B%EF%BC%89"><span class="toc-number">3.</span> <span class="toc-text">Reverse Diffusion 逆扩散过程（Reverse 去噪过程）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-1"><span class="toc-number">3.1.</span> <span class="toc-text">数学基础</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F"><span class="toc-number">3.1.1.</span> <span class="toc-text">贝叶斯公式</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%90%8E%E9%AA%8C%E6%89%A9%E6%95%A3%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87-q-x-t-1-x-t-x-0"><span class="toc-number">3.2.</span> <span class="toc-text">后验扩散条件概率 $q(x_{t-1}|x_t,x_0)$</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%AA%E4%BA%BA%E7%90%86%E8%A7%A3"><span class="toc-number">4.</span> <span class="toc-text">个人理解</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><div class="content"><a class="title" href="/posts/5ea7715c/" title="2025愿望清单">2025愿望清单</a><time datetime="2025-01-03T11:09:47.000Z" title="发表于 2025-01-03 19:09:47">2025-01-03</time></div></div><div class="aside-list-item"><div class="content"><a class="title" href="/posts/826780ab/" title="SDXL">SDXL</a><time datetime="2024-12-27T05:23:39.000Z" title="发表于 2024-12-27 13:23:39">2024-12-27</time></div></div><div class="aside-list-item"><div class="content"><a class="title" href="/posts/f0775513/" title="DDPM">DDPM</a><time datetime="2024-12-26T10:35:25.000Z" title="发表于 2024-12-26 18:35:25">2024-12-26</time></div></div><div class="aside-list-item"><div class="content"><a class="title" href="/posts/57e95ee9/" title="InstructSeg">InstructSeg</a><time datetime="2024-12-26T02:46:31.000Z" title="发表于 2024-12-26 10:46:31">2024-12-26</time></div></div><div class="aside-list-item"><div class="content"><a class="title" href="/posts/28a6509c/" title="ViLLa">ViLLa</a><time datetime="2024-12-25T03:08:24.000Z" title="发表于 2024-12-25 11:08:24">2024-12-25</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By Corn</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true}});</script></body></html>