<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>大模型训练 | Corn Field</title><meta name="author" content="Corn"><meta name="copyright" content="Corn"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Pipeline 并行 链接： https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;613196255 为什么要这么设计 模型越来越大，可能导致两个问题：">
<meta property="og:type" content="article">
<meta property="og:title" content="大模型训练">
<meta property="og:url" content="https://cornfield404.github.io/posts/2f6d7684/index.html">
<meta property="og:site_name" content="Corn Field">
<meta property="og:description" content="Pipeline 并行 链接： https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;613196255 为什么要这么设计 模型越来越大，可能导致两个问题：">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cornfield404.github.io/img/avatar.jpg">
<meta property="article:published_time" content="2025-04-02T05:46:16.000Z">
<meta property="article:modified_time" content="2025-05-08T07:54:31.061Z">
<meta property="article:author" content="Corn">
<meta property="article:tag" content="大模型">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cornfield404.github.io/img/avatar.jpg"><link rel="shortcut icon" href="/img/butterfly-icon.png"><link rel="canonical" href="https://cornfield404.github.io/posts/2f6d7684/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '大模型训练',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  isShuoshuo: false
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">52</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">53</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">14</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-book"></i><span> 技术积累</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"><i class="fa-fw fa fa-code"></i><span> 编程技巧</span></a></li><li><a class="site-page child" href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><i class="fa-fw fa fa-newspaper"></i><span> 论文笔记</span></a></li><li><a class="site-page child" href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"><i class="fa-fw fa fa-book-open"></i><span> 读书笔记</span></a></li><li><a class="site-page child" href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/%E5%8D%9A%E5%AE%A2%E7%AC%94%E8%AE%B0/"><i class="fa-fw fa fa-blog"></i><span> 博客笔记</span></a></li><li><a class="site-page child" href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"><i class="fa-fw fa fa-paperclip"></i><span> 杂七杂八</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-clapperboard"></i><span> 休闲娱乐</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/%E4%BC%91%E9%97%B2%E5%A8%B1%E4%B9%90/%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB/"><i class="fa-fw fa fa-book-open-reader"></i><span> 书籍阅读</span></a></li><li><a class="site-page child" href="/categories/%E4%BC%91%E9%97%B2%E5%A8%B1%E4%B9%90/%E8%88%9E%E5%8F%B0%E6%AC%A3%E8%B5%8F/"><i class="fa-fw fa fa-music"></i><span> 舞台欣赏</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-camera"></i><span> 生活琐事</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/%E7%94%9F%E6%B4%BB%E7%90%90%E4%BA%8B/%E7%A5%9E%E5%A5%87%E6%8A%80%E8%83%BD/"><i class="fa-fw fa fa-person-skating"></i><span> 神奇技能</span></a></li><li><a class="site-page child" href="/categories/%E7%94%9F%E6%B4%BB%E7%90%90%E4%BA%8B/%E6%97%85%E6%B8%B8%E8%AE%B0%E5%BD%95/"><i class="fa-fw fa fa-suitcase"></i><span> 旅游记录</span></a></li><li><a class="site-page child" href="/categories/%E7%94%9F%E6%B4%BB%E7%90%90%E4%BA%8B/%E7%82%B9%E7%82%B9%E6%BB%B4%E6%BB%B4/"><i class="fa-fw fa fa-puzzle-piece"></i><span> 点点滴滴</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-folder-open"></i><span> 整理</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-th"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-bars"></i><span> 其他</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/random.html"><i class="fa-fw fas fa-random"></i><span> 随便逛逛</span></a></li><li><a class="site-page child" href="/artitalk/"><i class="fa-fw fa fa-heartbeat"></i><span> 碎碎念</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fa fa-user"></i><span> 关于我</span></a></li><li><a class="site-page child" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/sitemap.xml"><i class="fa-fw fa fa-sitemap"></i><span> 站点地图</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://yumiwawa-1300546587.cos.ap-beijing.myqcloud.com/Obsidian/background.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Corn Field</span></a><a class="nav-page-title" href="/"><span class="site-name">大模型训练</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-book"></i><span> 技术积累</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"><i class="fa-fw fa fa-code"></i><span> 编程技巧</span></a></li><li><a class="site-page child" href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><i class="fa-fw fa fa-newspaper"></i><span> 论文笔记</span></a></li><li><a class="site-page child" href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"><i class="fa-fw fa fa-book-open"></i><span> 读书笔记</span></a></li><li><a class="site-page child" href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/%E5%8D%9A%E5%AE%A2%E7%AC%94%E8%AE%B0/"><i class="fa-fw fa fa-blog"></i><span> 博客笔记</span></a></li><li><a class="site-page child" href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"><i class="fa-fw fa fa-paperclip"></i><span> 杂七杂八</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-clapperboard"></i><span> 休闲娱乐</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/%E4%BC%91%E9%97%B2%E5%A8%B1%E4%B9%90/%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB/"><i class="fa-fw fa fa-book-open-reader"></i><span> 书籍阅读</span></a></li><li><a class="site-page child" href="/categories/%E4%BC%91%E9%97%B2%E5%A8%B1%E4%B9%90/%E8%88%9E%E5%8F%B0%E6%AC%A3%E8%B5%8F/"><i class="fa-fw fa fa-music"></i><span> 舞台欣赏</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-camera"></i><span> 生活琐事</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/%E7%94%9F%E6%B4%BB%E7%90%90%E4%BA%8B/%E7%A5%9E%E5%A5%87%E6%8A%80%E8%83%BD/"><i class="fa-fw fa fa-person-skating"></i><span> 神奇技能</span></a></li><li><a class="site-page child" href="/categories/%E7%94%9F%E6%B4%BB%E7%90%90%E4%BA%8B/%E6%97%85%E6%B8%B8%E8%AE%B0%E5%BD%95/"><i class="fa-fw fa fa-suitcase"></i><span> 旅游记录</span></a></li><li><a class="site-page child" href="/categories/%E7%94%9F%E6%B4%BB%E7%90%90%E4%BA%8B/%E7%82%B9%E7%82%B9%E6%BB%B4%E6%BB%B4/"><i class="fa-fw fa fa-puzzle-piece"></i><span> 点点滴滴</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-folder-open"></i><span> 整理</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-th"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-bars"></i><span> 其他</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/random.html"><i class="fa-fw fas fa-random"></i><span> 随便逛逛</span></a></li><li><a class="site-page child" href="/artitalk/"><i class="fa-fw fa fa-heartbeat"></i><span> 碎碎念</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fa fa-user"></i><span> 关于我</span></a></li><li><a class="site-page child" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/sitemap.xml"><i class="fa-fw fa fa-sitemap"></i><span> 站点地图</span></a></li></ul></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">大模型训练</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-04-02T05:46:16.000Z" title="发表于 2025-04-02 13:46:16">2025-04-02</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-05-08T07:54:31.061Z" title="更新于 2025-05-08 15:54:31">2025-05-08</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/">技术积累</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/%E5%8D%9A%E5%AE%A2%E7%AC%94%E8%AE%B0/">博客笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>3分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h2 id="Pipeline-并行">Pipeline 并行</h2>
<p>链接： <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/613196255">https://zhuanlan.zhihu.com/p/613196255</a></p>
<h3 id="为什么要这么设计">为什么要这么设计</h3>
<p>模型越来越大，可能导致两个问题：</p>
<ol>
<li>中间结果占据的空间越来越大（中间结果需要保存以用来做 bp）；</li>
<li>模型大到无法在单张卡上运行的情况下，需要把模型拆分到不同的卡上运行，如果采用串行（0 号卡算完一个，1 号卡计算，所有卡算法后，最后一张卡计算 bp，然后逐步传回 0 号卡）则 GPU 利用率非常低。<br>
<img src="https://yumiwawa-1300546587.cos.ap-beijing.myqcloud.com/Obsidian/20250508102648.png" width="50%" height="50%" /></li>
</ol>
<h3 id="解决办法">解决办法</h3>
<ol>
<li>针对第一个问题，可以不保存所有中间结果，仅保留上一张卡传入的输入，其余中间结果丢弃，需要计算的时候再重算一遍（时间换空间）；</li>
<li>针对第二个问题，把每个 batch 拆分成更小的 mini-batch，每个 mini-batch 计算完就把结果传到下一个卡，然后计算下一个 mini-batch，以提升 GPU 利用率。<br>
<img src="https://yumiwawa-1300546587.cos.ap-beijing.myqcloud.com/Obsidian/20250508102828.png" width="50%" height="50%" /></li>
</ol>
<hr>
<h2 id="数据并行">数据并行</h2>
<p>链接： <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/617133971">https://zhuanlan.zhihu.com/p/617133971</a> ； <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/618865052">https://zhuanlan.zhihu.com/p/618865052</a></p>
<h3 id="核心思路">核心思路</h3>
<p>在每个 GPU 上拷贝一份完整的模型，各自用一份数据计算一份梯度，然后对梯度进行累加来更新整体梯度。</p>
<h3 id="DP">DP</h3>
<h4 id="流程">流程</h4>
<ul>
<li>在每块计算 GPU 上拷贝一份完整的模型参数；</li>
<li>把一份数据均匀分给不同的计算 GPU；</li>
<li>每块 GPU 进行 forward 和 backward 计算后，得到一份梯度 G；</li>
<li>每块计算 GPU 将自己计算得到的梯度传给梯度收集 GPU，进行聚合操作；</li>
<li>梯度收集 GPU 聚合完毕后，计算 GPU 获取完整的梯度结果，用于更新模型参数。</li>
</ul>
<h4 id="DP-存在的问题">DP 存在的问题</h4>
<ol>
<li>存储开销大：每块 GPU 上都保存了完整的模型，造成冗余；</li>
<li>通讯开销大：当梯度收集 GPU 与计算 GPU 不在同一台机器上时，传输带宽会成为效率瓶颈。</li>
</ol>
<h3 id="DDP">DDP</h3>
<h4 id="核心思路-2">核心思路</h4>
<p>利用 Ring-AllReduce，把通讯量均分到每个 GPU 卡上，降低因通讯量集中在某几个卡上导致的延迟。</p>
<h4 id="具体流程示意图">具体流程示意图</h4>
<img src="https://yumiwawa-1300546587.cos.ap-beijing.myqcloud.com/Obsidian/20250508142345.png" width="50%" height="50%" />
<img src="https://yumiwawa-1300546587.cos.ap-beijing.myqcloud.com/Obsidian/20250508142351.png" width="50%" height="50%" />
<img src="https://yumiwawa-1300546587.cos.ap-beijing.myqcloud.com/Obsidian/20250508142418.png" width="50%" height="50%" />
<img src="https://yumiwawa-1300546587.cos.ap-beijing.myqcloud.com/Obsidian/20250508142423.png" width="50%" height="50%" />
<h4 id="通讯量">通讯量</h4>
<p>单卡通讯量为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">2\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">2Φ</span></span></span></span>，全卡通讯量为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>N</mi><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">2N\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord">Φ</span></span></span></span>。</p>
<h3 id="DeepSpeed-ZeRO">DeepSpeed ZeRO</h3>
<h4 id="优化目标">优化目标</h4>
<p>在大模型中，如果每个 GPU 上都复制一份完整模型，会造成大量冗余且很容易导致 GPU 显存不够用。因此 ZeRO 的主要目标是优化显存占用。</p>
<h4 id="显存占用分析">显存占用分析</h4>
<ul>
<li>首先从混合精度训练流程出发，分析显存占用主要由哪些部分构成：<br>
<img src="https://yumiwawa-1300546587.cos.ap-beijing.myqcloud.com/Obsidian/20250508150307.png" width="50%" height="50%" /></li>
<li>GPU 必须存储的内容：
<ul>
<li>Optimizer states：Adam 优化算法中的 momentum 和 variance；</li>
<li>Gradients：模型梯度；</li>
<li>Parameters：模型参数。</li>
</ul>
</li>
<li>考虑到 fp32 占 4 byte，fp16 占 2 byte，存储量与参数量之间的关系：<br>
<img src="https://yumiwawa-1300546587.cos.ap-beijing.myqcloud.com/Obsidian/20250508151345.png" width="50%" height="50%" /></li>
</ul>
<h4 id="ZeRO-DP-优化方式">ZeRO-DP 优化方式</h4>
<ul>
<li>主要优化思路是，每个 GPU 仅保存一部分参数，需要的时候从其他 GPU 同步过来，计算完成后丢弃不需要的部分，以通讯换空间。</li>
<li>具体流程：
<ul>
<li>每块 GPU 上仅保存部分参数、梯度以及优化器状态；</li>
<li>Forward 时，对权重进行一次聚合，得到完整的权重进行 forward 计算，计算完成后，丢弃其余部分的权重，聚合操作的单卡通讯量为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Φ</span></span></span></span>；</li>
<li>进行 backward 时，对权重进行一次聚合，得到完整的权重进行 backward 计算，计算完成后，丢弃其余部分的权重，聚合操作的单卡通讯量为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Φ</span></span></span></span>；</li>
<li>做完 backward，计算一份完整的梯度，对梯度进行一次聚合，每个 GPU 仅需保证自己保存的那部分梯度是聚合了所有 GPU 之后的结果，不需要保证所有梯度都是对的，因此该步操作的单卡通讯量为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Φ</span></span></span></span> 而不是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">2\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">2Φ</span></span></span></span>；</li>
<li>用每块 GPU 自己维护的梯度及优化器状态更新自己维护的参数。</li>
</ul>
</li>
<li>与每张 GPU 保存所有参数相比，ZeRO 通讯量增加并不明显，仅仅增加了 1.5 倍，但可以大幅降低显存占用。</li>
</ul>
<hr>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://cornfield404.github.io">Corn</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://cornfield404.github.io/posts/2f6d7684/">https://cornfield404.github.io/posts/2f6d7684/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://cornfield404.github.io" target="_blank">Corn Field</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/">大模型</a></div><div class="post-share"><div class="social-share" data-image="/img/avatar.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/posts/41b83f0a/" title="青春学院"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">青春学院</div></div><div class="info-2"><div class="info-item-1">整体感受 整体是一次非常差的观剧体验，首先买票的时候买的是《列车黄金大劫案》的票，也就是一个推理的剧本，现场所有人也都是为了推理剧本付的钱。结果当天到场后才通知因有演员生病，所以原定的剧目没办法演，临时改成了《青春学院》。也就是说，第一剧组没有备卡，第二无法正常表演没有提前通知，第三临时把演出内容换得毫不相干。 其次，作为一个 i 人，买票的时候我特意买了互动度最低的那一档的票，准备美美做个吃瓜群众，欣赏演员和 e...</div></div></div></a><a class="pagination-related" href="/posts/6ed5720f/" title="【DeepSeek系列（一）】DeepSeek LLM"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">【DeepSeek系列（一）】DeepSeek LLM</div></div><div class="info-2"><div class="info-item-1">【DeepSeek系列（一）】DeepSeek LLM【DeepSeek系列（二）】DeepSeek Coder 题目： DeepSeek LLM Scaling Open-Source Language Models with Longtermism 链接： 2401.02954 代码： GitHub - deepseek-ai/DeepSeek-LLM: DeepSeek LLM: Let there be answers 单位： DeepSeek-AI  本文目的 研究了语言模型中的 scaling 问题，之前的论文要么忽略了 scaling 问题，要么对于该问题研究不够充分，本文希望得到一个更可靠的结论。 具体来说，本文先研究了随着模型大小变化，batch size 和 learning rate 的 scaling law。在此基础上，对模型和数据的 scaling law 进行了全面研究，并据此预测了大模型的表现。此外，在开发过程中，还发现了在不同数据集上会得到不同的 scaling...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/posts/c0dbd124/" title="【DeepSeek系列（二）】DeepSeek Coder"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-21</div><div class="info-item-2">【DeepSeek系列（二）】DeepSeek Coder</div></div><div class="info-2"><div class="info-item-1">【DeepSeek系列（一）】DeepSeek LLM【DeepSeek系列（二）】DeepSeek Coder 题目： DeepSeek-Coder: When the Large Language Model Meets Programming - The Rise of Code Intelligence 链接： 2401.14196 代码： GitHub - deepseek-ai/DeepSeek-Coder: DeepSeek Coder: Let the Code Write Itself 单位： DeepSeek-AI；Key Lab of HCST (PKU), MOE; SCS, Peking University  数据 数据收集 训练数据包括 87%的源代码，10%的与代码相关的英文自然语言语料库以及 3%与代码无关的中文自然语言语料库。 其中，英语语料库由 github 的 markdown 文档及 StackExchange 构成，用于帮助模型理解代码相关的概念，并且提升模型在 library 调用以及 bug...</div></div></div></a><a class="pagination-related" href="/posts/6ed5720f/" title="【DeepSeek系列（一）】DeepSeek LLM"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-18</div><div class="info-item-2">【DeepSeek系列（一）】DeepSeek LLM</div></div><div class="info-2"><div class="info-item-1">【DeepSeek系列（一）】DeepSeek LLM【DeepSeek系列（二）】DeepSeek Coder 题目： DeepSeek LLM Scaling Open-Source Language Models with Longtermism 链接： 2401.02954 代码： GitHub - deepseek-ai/DeepSeek-LLM: DeepSeek LLM: Let there be answers 单位： DeepSeek-AI  本文目的 研究了语言模型中的 scaling 问题，之前的论文要么忽略了 scaling 问题，要么对于该问题研究不够充分，本文希望得到一个更可靠的结论。 具体来说，本文先研究了随着模型大小变化，batch size 和 learning rate 的 scaling law。在此基础上，对模型和数据的 scaling law 进行了全面研究，并据此预测了大模型的表现。此外，在开发过程中，还发现了在不同数据集上会得到不同的 scaling...</div></div></div></a><a class="pagination-related" href="/posts/5c298aee/" title="GPT"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-07</div><div class="info-item-2">GPT</div></div><div class="info-2"><div class="info-item-1">题目： Improving Language Understanding by Generative Pre-Training 链接： language_understanding_paper.pdf 单位： OpenAI  目标 设计一个利用无标签数据进行 pretrain 的方法，使 pretrain 模型可以在利用少量标注数据 finetune 后就在下游任务上取得比较好的效果。  Framework Unsupervised pre-training 模型由多层 transformer decoder 构成，训练任务是由之前的 context 预测文本的下一个 token。 Supervised fine-tuning 在预训练模型基础上，增加 head，用 head 完成特定的任务，训练时仅训练 head 的参数。 Task-specific input transformations 针对不同任务设计了不同的处理方式。   题目： Language Models are Unsupervised Multitask Learners 链接：...</div></div></div></a><a class="pagination-related" href="/posts/f8889f73/" title="不同VLLM比较"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-11</div><div class="info-item-2">不同VLLM比较</div></div><div class="info-2"><div class="info-item-1">整体来说不同模型的技术在逐渐趋同，最开始的大家尝试了一些不同的方案，比如 deepseek 用了两个视觉模型提取不同分辨率的特征，internvl 设计了非常复杂的训练流程，但是在产品迭代过程中这些都被舍弃掉了。 目前 deepseek、internvl 和 qwen 比较起来：  Deepseek 在视觉模型部分没有什么突出的特点，就是图像切成块输入+SigLIP； Internvl 主要有一个自己训的 6B 以及蒸馏的 300M 视觉模型； Qwen 可以接受任意尺度的图像输入，不需要像其他模型一样切块，同时设计了一个多维位置编码，用于适应视频输入。  </div></div></div></a><a class="pagination-related" href="/posts/e0d8505c/" title="QwenVL"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-11</div><div class="info-item-2">QwenVL</div></div><div class="info-2"><div class="info-item-1">题目： Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond 链接： 2308.12966 代码： GitHub - QwenLM/Qwen-VL: The official repo of Qwen-VL (通义千问-VL) chat &amp; pretrained large vision language model proposed by Alibaba Cloud. 来源： arxiv 单位： Alibaba Group  题目： Qwen 2-VL: Enhancing Vision-Language Model’s Perception of the World at Any Resolution 链接： https://arxiv.org/pdf/2409.12191 代码： https://github.com/QwenLM/Qwen2-VL 来源： arxiv 单位： Qwen Team Alibaba...</div></div></div></a><a class="pagination-related" href="/posts/59ecffa9/" title="InternVL"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-11</div><div class="info-item-2">InternVL</div></div><div class="info-2"><div class="info-item-1">题目： InternVL: Scaling up Vision Foundation Models and Aligning For Generic Visual-Linguistic Tasks 链接： 2312.14238 代码： GitHub - OpenGVLab/InternVL: [CVPR 2024 Oral] InternVL Family: A Pioneering Open-Source Alternative to GPT-4o. 接近GPT-4o表现的开源多模态对话模型 来源： CVPR 2024 单位： OpenGVLab, Shanghai AI Laboratory；Nanjing University；The University of Hong Kong；The Chinese University of Hong Kong；Tsinghua University；University of Science and Technology of China；SenseTime Research  题目： How Far Are We to...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="waline-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Corn</div><div class="author-info-description">来者可追</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">52</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">53</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">14</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Pipeline-%E5%B9%B6%E8%A1%8C"><span class="toc-number">1.</span> <span class="toc-text">Pipeline 并行</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%BF%99%E4%B9%88%E8%AE%BE%E8%AE%A1"><span class="toc-number">1.1.</span> <span class="toc-text">为什么要这么设计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95"><span class="toc-number">1.2.</span> <span class="toc-text">解决办法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C"><span class="toc-number">2.</span> <span class="toc-text">数据并行</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%80%9D%E8%B7%AF"><span class="toc-number">2.1.</span> <span class="toc-text">核心思路</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DP"><span class="toc-number">2.2.</span> <span class="toc-text">DP</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%81%E7%A8%8B"><span class="toc-number">2.2.1.</span> <span class="toc-text">流程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#DP-%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">2.2.2.</span> <span class="toc-text">DP 存在的问题</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DDP"><span class="toc-number">2.3.</span> <span class="toc-text">DDP</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%80%9D%E8%B7%AF-2"><span class="toc-number">2.3.1.</span> <span class="toc-text">核心思路</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E6%B5%81%E7%A8%8B%E7%A4%BA%E6%84%8F%E5%9B%BE"><span class="toc-number">2.3.2.</span> <span class="toc-text">具体流程示意图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%9A%E8%AE%AF%E9%87%8F"><span class="toc-number">2.3.3.</span> <span class="toc-text">通讯量</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DeepSpeed-ZeRO"><span class="toc-number">2.4.</span> <span class="toc-text">DeepSpeed ZeRO</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E7%9B%AE%E6%A0%87"><span class="toc-number">2.4.1.</span> <span class="toc-text">优化目标</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90"><span class="toc-number">2.4.2.</span> <span class="toc-text">显存占用分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ZeRO-DP-%E4%BC%98%E5%8C%96%E6%96%B9%E5%BC%8F"><span class="toc-number">2.4.3.</span> <span class="toc-text">ZeRO-DP 优化方式</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/2f6d7684/" title="大模型训练">大模型训练</a><time datetime="2025-05-08T07:54:31.061Z" title="更新于 2025-05-08 15:54:31">2025-05-08</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/826780ab/" title="SDXL">SDXL</a><time datetime="2025-05-08T02:08:16.799Z" title="更新于 2025-05-08 10:08:16">2025-05-08</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/c0dbd124/" title="【DeepSeek系列（二）】DeepSeek Coder">【DeepSeek系列（二）】DeepSeek Coder</a><time datetime="2025-05-08T02:07:37.634Z" title="更新于 2025-05-08 10:07:37">2025-05-08</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/ccff5ff7/" title="2025-04-15 旅行手帐完全指南读后碎碎念.md">2025-04-15 旅行手帐完全指南读后碎碎念.md</a><time datetime="2025-05-07T10:32:49.296Z" title="更新于 2025-05-07 18:32:49">2025-05-07</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/8158fb05/" title="种草书单">种草书单</a><time datetime="2025-04-29T02:17:35.265Z" title="更新于 2025-04-29 10:17:35">2025-04-29</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By Corn</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  let initFn = window.walineFn || null
  const isShuoshuo = GLOBAL_CONFIG_SITE.isShuoshuo
  const option = null

  const destroyWaline = ele => ele.destroy()

  const initWaline = (Fn, el = document, path = window.location.pathname) => {
    const waline = Fn({
      el: el.querySelector('#waline-wrap'),
      serverURL: 'hexowaline-ten.vercel.app',
      pageview: false,
      dark: 'html[data-theme="dark"]',
      comment: false,
      ...option,
      path: isShuoshuo ? path : (option && option.path) || path
    })

    if (isShuoshuo) {
      window.shuoshuoComment.destroyWaline = () => {
        destroyWaline(waline)
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const loadWaline = (el, path) => {
    if (initFn) initWaline(initFn, el, path)
    else {
      btf.getCSS('https://cdn.jsdelivr.net/npm/@waline/client/dist/waline.min.css')
        .then(() => import('https://cdn.jsdelivr.net/npm/@waline/client/dist/waline.min.js'))
        .then(({ init }) => {
          initFn = init || Waline.init
          initWaline(initFn, el, path)
          window.walineFn = initFn
        })
    }
  }

  if (isShuoshuo) {
    'Waline' === 'Waline'
      ? window.shuoshuoComment = { loadComment: loadWaline } 
      : window.loadOtherComment = loadWaline
    return
  }

  if ('Waline' === 'Waline' || !false) {
    if (false) btf.loadComment(document.getElementById('waline-wrap'),loadWaline)
    else setTimeout(loadWaline, 0)
  } else {
    window.loadOtherComment = loadWaline
  }
})()</script></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true}});</script></body></html>